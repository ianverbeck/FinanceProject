{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from urllib.request import urlopen  \n",
    "import json\n",
    "\n",
    "getkey = ! cat ../../apikey.txt\n",
    "apikey = getkey[0]\n",
    "\n",
    "from fhelp import get_appended,process_datesIT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['CRM', 'WBA', 'V', 'NKE', 'UNH', 'TRV', 'VZ', 'INTC', 'WMT', 'JNJ', 'DIS', 'MCD', 'JPM', 'CAT', 'BA', 'AMGN', 'DOW', 'AAPL', 'GS', 'CSCO', 'MSFT', 'HD', 'PG', 'MRK', 'IBM', 'HON', 'KO', 'CVX', 'AXP', 'MMM']\n"
     ]
    }
   ],
   "source": [
    "#get list of tickers (just dow until everything is set up)\n",
    "dow_url = \"https://financialmodelingprep.com/api/v3/dowjones_constituent?apikey=600e501fe324b2f1cbb2aec5b390b6db\"\n",
    "dow_tick = pd.read_json(dow_url)\n",
    "tickers = list(dow_tick.symbol.values)\n",
    "print(tickers,)\n",
    "tickers += ['SECO']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "indexes = None\n",
    "etfs = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "! rm ../../Finances.db\n",
    "! rm schema.sql"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "urls = pd.read_json('Resources/urls.json',typ='series')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn = sqlite3.connect('../../Finances.db')\n",
    "c = conn.cursor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "l = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "tickers = ['AAPL','']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "H1b1000_CV_PROFILE\n",
      "H1b1000_CV_QUOTE\n",
      "S1_CV_EXECUTIVES\n",
      "Downloading for ticker AAPL....\n",
      "UG1_CV_SEARCH\n",
      "S1_CV_FS_INCOME_YR\n",
      "Downloading for ticker AAPL....\n",
      "S1_CV_FS_INCOME_QTR\n",
      "Downloading for ticker AAPL....\n",
      "S1_CV_FS_BALANCESHEET_YR\n",
      "Downloading for ticker AAPL....\n",
      "S1_CV_FS_BALANCESHEET_QTR\n",
      "Downloading for ticker AAPL....\n",
      "S1_CV_FS_CASHFLOW_YR\n",
      "Downloading for ticker AAPL....\n",
      "S1_CV_FS_CASHFLOW_QTR\n",
      "Downloading for ticker AAPL....\n",
      "S1_CV_FS_INCOMEGROWTH_YR\n",
      "Downloading for ticker AAPL....\n",
      "S1_CV_FS_BALANCEGROWTH_YR\n",
      "Downloading for ticker AAPL....\n",
      "S1_CV_FS_CASHGROWTH_YR\n",
      "Downloading for ticker AAPL....\n",
      "UT1_CV_INTLFILINGS\n",
      "US1_CV_FS_ASREPORTED\n",
      "S1_CV_RATIOS_TTM\n",
      "Downloading for ticker AAPL....\n",
      "S1_CV_RATIOS_YR\n",
      "Downloading for ticker AAPL....\n",
      "S1_CV_RATIOS_QTR\n",
      "Downloading for ticker AAPL....\n",
      "S1_CV_ENTERPRISEVALUE_YR\n",
      "Downloading for ticker AAPL....\n",
      "S1_CV_ENTERPRISEVALUE_QTR\n",
      "Downloading for ticker AAPL....\n",
      "S1_CV_METRICS_TTM\n",
      "Downloading for ticker AAPL....\n",
      "S1_CV_METRICS_YR\n",
      "Downloading for ticker AAPL....\n",
      "S1_CV_METRICS_QTR\n",
      "Downloading for ticker AAPL....\n",
      "S1_CV_GROWTH_YR\n",
      "Downloading for ticker AAPL....\n",
      "S1_CV_GROWTH_QTR\n",
      "Downloading for ticker AAPL....\n",
      "S1_CV_RATING\n",
      "Downloading for ticker AAPL....\n",
      "S1_CV_RATING_DAY\n",
      "Downloading for ticker AAPL....\n",
      "S1_CV_DCF\n",
      "Downloading for ticker AAPL....\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-9-d59c3906bbe6>:20: UserWarning: The spaces in these column names will not be changed. In pandas versions < 0.14, spaces were converted to underscores.\n",
      "  a = pd.io.sql.get_schema(tab,name)\n",
      "/Users/verbeck/opt/anaconda3/envs/jupyterlab-debugger/lib/python3.9/site-packages/pandas/core/generic.py:2778: UserWarning: The spaces in these column names will not be changed. In pandas versions < 0.14, spaces were converted to underscores.\n",
      "  sql.to_sql(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "S2_CV_DCF_YR\n",
      "Downloading for ticker AAPL....\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-9-d59c3906bbe6>:20: UserWarning: The spaces in these column names will not be changed. In pandas versions < 0.14, spaces were converted to underscores.\n",
      "  a = pd.io.sql.get_schema(tab,name)\n",
      "/Users/verbeck/opt/anaconda3/envs/jupyterlab-debugger/lib/python3.9/site-packages/pandas/core/generic.py:2778: UserWarning: The spaces in these column names will not be changed. In pandas versions < 0.14, spaces were converted to underscores.\n",
      "  sql.to_sql(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "S2_CV_DCF_QTR\n",
      "Downloading for ticker AAPL....\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-9-d59c3906bbe6>:20: UserWarning: The spaces in these column names will not be changed. In pandas versions < 0.14, spaces were converted to underscores.\n",
      "  a = pd.io.sql.get_schema(tab,name)\n",
      "/Users/verbeck/opt/anaconda3/envs/jupyterlab-debugger/lib/python3.9/site-packages/pandas/core/generic.py:2778: UserWarning: The spaces in these column names will not be changed. In pandas versions < 0.14, spaces were converted to underscores.\n",
      "  sql.to_sql(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "S1_CV_DCF_DAY\n",
      "Downloading for ticker AAPL....\n",
      "S1_CV_MARKETCAP\n",
      "Downloading for ticker AAPL....\n",
      "S1_CV_MARKETCAP_DAY\n",
      "Downloading for ticker AAPL....\n",
      "G1_CV_SYMBOLS\n",
      "G1_CV_ETFS\n",
      "G1_CV_TRADABLE\n",
      "UG1_CV_BATCHREQUEST\n",
      "UG1_CV_STOCKSCREENER\n",
      "G1_CV_DELISTED\n",
      "T1b1000_CV_NEWS\n",
      "US1_CV_EARNINGSCALLTRANSCRIPT\n",
      "US1_CV_EARNINGSSURPRISES\n",
      "UT1_CV_SECFILINGS\n",
      "T1_CV_PRESSRELEASES\n",
      "Downloading for ticker AAPL....\n",
      "S1_INS_STOCKTRADING\n",
      "Downloading for ticker AAPL....\n",
      "UG1_INS_RSSFEED\n",
      "G1_CAL_EARNINGSCALENDAR_UPC\n",
      "S1_CAL_EARNINGSCALENDAR_HIST\n",
      "Downloading for ticker AAPL....\n",
      "UG1_CAL_IPO\n",
      "UG1_CAL_SPLITS\n",
      "UG1_CAL_DIVIDENDS\n",
      "UG1_CAL_ECONOMIC\n",
      "T1_INST_HOLDERS\n",
      "Downloading for ticker AAPL....\n",
      "T1_INST_MUTFUNDHOLDERS\n",
      "Downloading for ticker AAPL....\n",
      "E1_INST_ETFHOLDERS\n",
      "E1_INST_ETFSECTORWEIGHTS\n",
      "E1_INST_ETFCOUNTRYWEIGHTS\n",
      "UG1_INST_SECRSSFEED\n",
      "G1_INST_CIKLIST\n",
      "F1_INST_13F\n",
      "UT1_TS_PRICE\n",
      "UX1_TS_PRICELIST\n",
      "H3b5_TS_PRICE_DAY\n",
      "H3b5_TS_DIVIDENDS_HIST\n",
      "H3b5_TS_SPLITS_HIST\n",
      "UT1_TS_BIASFREE\n",
      "UT1_TI_DAILY\n",
      "UT1_TI_INTRADAY\n",
      "G1_MI_MAJORINDEXES\n",
      "G1_MI_SP500LIST\n",
      "G1_MI_SP500HIST\n",
      "G1_MI_NASDAQLIST\n",
      "G1_MI_NASDAQHISTLIST\n",
      "G1_MI_DOWJLIST\n",
      "G1_MI_DOWJHISTLIST\n",
      "I1b5_MI_INDEXPRICEHIST_DAY\n",
      "UG1_AD_COTSYMBOLLIST\n",
      "UG1_AD_COTREPORT\n",
      "UG1_AD_COTANALYSIS\n",
      "G1_COM_SYMBOLS\n",
      "G1_COM_PRICES\n",
      "UC2_COM_PRICES_DAY\n",
      "G1_ETF_SYMBOLS\n",
      "G1_ETF_PRICES\n",
      "U_ETF_PRICES_DAY\n",
      "G1_MF_SYMBOLS\n",
      "G1_MF_PRICES\n",
      "U_MF_PRICES_DAY\n",
      "U_EURO_PRICES\n",
      "U_EURO_PRICES_DAY\n",
      "U_TSX_PRICES\n",
      "U_TSX_PRICES_DAY\n",
      "U_SM_ACTIVE\n",
      "U_SM_GAINER\n",
      "U_SM_LOSER\n",
      "U_SM_HOURS\n",
      "U_SM_SECTORPERFORMANCE\n",
      "U_CRYPT_PRICES\n",
      "U_CRYPT_PRICES_DAY\n",
      "U_FX_PRICES\n",
      "U_FX_PRICES_DAY\n"
     ]
    }
   ],
   "source": [
    "#%%time\n",
    "schemas = open(\"schema.sql\", \"a+\")\n",
    "for name, url in zip(urls.index,urls.values):\n",
    "    print(name)\n",
    "    if url =='NONE' or name[0] == 'U':\n",
    "            continue\n",
    "    if type(url) != dict:\n",
    "        #extract\n",
    "        if name[0]=='G': #if ticker info not needed\n",
    "            tab = get_appended(url,apikey,name,verbose=True)\n",
    "        elif name[0] == 'S' or name[0] == 'T' or name[0] == 'H':\n",
    "            tab = get_appended(url,apikey,name,tickers=tickers,verbose=True)\n",
    "        if len(tab) == 0: \n",
    "            #log error\n",
    "            continue\n",
    "        tab.reset_index(inplace=True,drop=True)\n",
    "        tab.drop_duplicates(inplace=True)\n",
    "        #load\n",
    "        l.append(tab)\n",
    "        a = pd.io.sql.get_schema(tab,name)\n",
    "        c.execute('drop table if exists '+ name)\n",
    "        c.execute(a)\n",
    "        tosql = a +';\\n\\n'\n",
    "        schemas.write(tosql)\n",
    "        tab.to_sql(name,con=conn,index=False,if_exists='append')\n",
    "    else: \n",
    "        for i, u in enumerate(url.values()):\n",
    "            print(u)\n",
    "            if i == 1: \n",
    "                #extract\n",
    "                tab = get_appended(u,apikey,tickers,verbose=True)\n",
    "                #transform\n",
    "                tab.drop_duplicates(inplace=True)\n",
    "                #load\n",
    "                a = pd.io.sql.get_schema(tab,name)\n",
    "                c.execute('drop table if exists '+ name)\n",
    "                c.execute(a)\n",
    "                tosql = a +';\\n\\n'\n",
    "                schemas.write(tosql)\n",
    "                tab.to_sql(name,con=conn,index=False,if_exists='append')\n",
    "                print(c.execute('select * from '+name+' limit 1;').fetchall())\n",
    "            else:\n",
    "                tab= get_appended(u,apikey,tickers,verbose=True)\n",
    "                tab.drop_duplicates(inplace=True)\n",
    "                tab.to_sql(name,con=conn,index=False,if_exists='append')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
