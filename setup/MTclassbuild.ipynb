{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from threading import Thread\n",
    "import concurrent.futures\n",
    "import time\n",
    "\n",
    "import sqlite3\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from urllib.request import urlopen  \n",
    "import json\n",
    "import requests\n",
    "\n",
    "getkey = ! cat ../../apikey.txt\n",
    "apikey = getkey[0]\n",
    "\n",
    "from fhelp import get_appended,processDatesIT\n",
    "from FMPGet import FMPGet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = FMPGet(apikey)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting General Data................\n",
      "G1_MI_MAJORINDEXES SUCCESS\n",
      "G1_CAL_EARNINGSCALENDAR_UPC SUCCESS\n",
      "G1_MI_SP500LIST SUCCESS\n",
      "G1_MI_NASDAQLIST SUCCESS\n",
      "G1_MI_SP500HIST SUCCESS\n",
      "G1_MI_DOWJLIST SUCCESS\n",
      "G1_MI_DOWJHISTLIST SUCCESS\n",
      "G1_MI_NASDAQHISTLIST SUCCESS\n",
      "G1_COM_SYMBOLS SUCCESS\n",
      "G1_INST_CIKLIST SUCCESS\n",
      "G1_COM_PRICES SUCCESS\n",
      "G1_CV_DELISTED SUCCESS\n",
      "G1_ETF_SYMBOLS SUCCESS\n",
      "G1_CV_ETFS SUCCESS\n",
      "G1_ETF_PRICES SUCCESS\n",
      "G1_MF_SYMBOLS SUCCESS\n",
      "G1_CV_SYMBOLS SUCCESS\n",
      "G1_MF_PRICES SUCCESS\n",
      "G1_CV_TRADABLE SUCCESS\n",
      "Retrieving dow-specific tickerset(funds,ciks,indexes,etc)\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "module 'pandas.io.sql' has no attribute 'read'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-33e51ea0cce7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0ma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Desktop/Finance/Technology/Project/Setup/FMPGet.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, verbose)\u001b[0m\n\u001b[1;32m     62\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0murls\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_json\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0murl_path\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtyp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'series'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getGeneral\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m##TO DO: Add extra output for verbose. Not priority now\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m         \u001b[0md\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getTickers\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getSpecific\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/Finance/Technology/Project/Setup/FMPGet.py\u001b[0m in \u001b[0;36m__getTickers\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    104\u001b[0m         \u001b[0;31m#pull stocks from database\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m         \u001b[0mtickertable\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'dow'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m'G1_MI_DOWLIST'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'ndaq100'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m'G1_MI_NASDAQLIST'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'sp500'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m'G1_MI_SP500LIST'\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 106\u001b[0;31m         \u001b[0mstocks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msql\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'select symbol from '\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mtickertable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtickerset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    107\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m         \u001b[0;31m#pull etfs & join\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'pandas.io.sql' has no attribute 'read'"
     ]
    }
   ],
   "source": [
    "a.run(verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "urls = pd.read_json('Resources/urls.json',typ='series')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "independents = urls[[name for name in urls.index if name[0] == 'G']]\n",
    "dependents = urls[[name for name in urls.index if name[0] != 'G' and name[0] != 'U']]\n",
    "unused = urls[[name for name in urls.index if name[0] == 'U']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rm: ../../FinancesTEST.db: No such file or directory\n"
     ]
    }
   ],
   "source": [
    "! rm ../../FinancesTEST.db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "urls = pd.read_json('Resources/urls.json',typ='series')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#conn = sqlite3.connect('../../Finances.db')\n",
    "conn = sqlite3.connect('FinancesTEST.db')\n",
    "c = conn.cursor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_url(pair,apikey):\n",
    "    name = pair[0]\n",
    "    url = pair[1]\n",
    "    tab = get_appended(url,apikey,name)\n",
    "    return tab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('G1_MI_MAJORINDEXES', 'https://financialmodelingprep.com/api/v3/quotes/index?apikey=') SUCCESS\n",
      "('G1_MI_SP500HIST', 'https://financialmodelingprep.com/api/v3/historical/sp500_constituent?apikey=') SUCCESS\n",
      "('G1_CAL_EARNINGSCALENDAR_UPC', 'https://financialmodelingprep.com/api/v3/earning_calendar?apikey=') SUCCESS\n",
      "('G1_MI_SP500LIST', 'https://financialmodelingprep.com/api/v3/sp500_constituent?apikey=') SUCCESS\n",
      "('G1_MI_NASDAQLIST', 'https://financialmodelingprep.com/api/v3/nasdaq_constituent?apikey=') SUCCESS\n",
      "('G1_MI_DOWJLIST', 'https://financialmodelingprep.com/api/v3/dowjones_constituent?apikey=') SUCCESS\n",
      "('G1_MI_DOWJHISTLIST', 'https://financialmodelingprep.com/api/v3/historical/dowjones_constituent?apikey=') SUCCESS\n",
      "('G1_COM_SYMBOLS', 'https://financialmodelingprep.com/api/v3/symbol/available-commodities?apikey=') SUCCESS\n",
      "('G1_MI_NASDAQHISTLIST', 'https://financialmodelingprep.com/api/v3/historical/nasdaq_constituent?apikey=') SUCCESS\n",
      "('G1_COM_PRICES', 'https://financialmodelingprep.com/api/v3/quotes/commodity?apikey=') SUCCESS\n",
      "('G1_ETF_SYMBOLS', 'https://financialmodelingprep.com/api/v3/symbol/available-etfs?apikey=') SUCCESS\n",
      "('G1_CV_DELISTED', 'https://financialmodelingprep.com/api/v3/delisted-companies?limit=1000000000&apikey=') SUCCESS\n",
      "('G1_CV_ETFS', 'https://financialmodelingprep.com/api/v3/etf/list?apikey=') SUCCESS\n",
      "('G1_INST_CIKLIST', 'https://financialmodelingprep.com/api/v3/cik_list?apikey=') SUCCESS\n",
      "('G1_ETF_PRICES', 'https://financialmodelingprep.com/api/v3/quotes/etf?apikey=') SUCCESS\n",
      "('G1_MF_SYMBOLS', 'https://financialmodelingprep.com/api/v3/symbol/available-mutual-funds?apikey=') SUCCESS\n",
      "('G1_CV_SYMBOLS', 'https://financialmodelingprep.com/api/v3/stock/list?apikey=') SUCCESS\n",
      "('G1_MF_PRICES', 'https://financialmodelingprep.com/api/v3/quotes/mutual_fund?apikey=') SUCCESS\n",
      "('G1_CV_TRADABLE', 'https://financialmodelingprep.com/api/v3/available-traded/list?apikey=') SUCCESS\n",
      "CPU times: user 1.19 s, sys: 207 ms, total: 1.4 s\n",
      "Wall time: 5.24 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "rate_limit = 10\n",
    "offset = 1/rate_limit\n",
    "max_workers = rate_limit -1\n",
    "with concurrent.futures.ThreadPoolExecutor(max_workers=max_workers) as executor:\n",
    "    # Start the load operations and mark each future with its URL\n",
    "    future_to_url = {executor.submit(load_url,pair,apikey): pair for pair in independents.iteritems()}\n",
    "    for future in concurrent.futures.as_completed(future_to_url):\n",
    "        time.sleep(offset)\n",
    "        pair = future_to_url[future]\n",
    "        try:\n",
    "            tab = future.result()\n",
    "        except Exception as exc:\n",
    "            print(pair,'FAILED',exc)\n",
    "            \n",
    "        else:\n",
    "            c.execute('drop table if exists '+ pair[0])\n",
    "            tab.to_sql(pair[0],con=conn,index=False,if_exists='append')\n",
    "            print(pair, 'SUCCESS')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#setup database\n",
    "###FULL lists for full set processing\n",
    "stocks = list(pd.io.sql.read_sql('select symbol from G1_CV_SYMBOLS;',con=conn).symbol)\n",
    "etfs  = list(pd.io.sql.read_sql('select symbol from G1_ETF_SYMBOLS;',con=conn).symbol)\n",
    "etfs2  = list(pd.io.sql.read_sql('select symbol from G1_CV_ETFS;',con=conn).symbol)\n",
    "indexes = list(pd.io.sql.read_sql('select symbol from G1_MI_MAJORINDEXES;',con=conn).symbol)\n",
    "ciks = ['000'+str(c) for c in list(pd.io.sql.read_sql('select cik from G1_INST_CIKLIST',con=conn).cik)]\n",
    "funds = list(pd.io.sql.read_sql('select symbol from G1_MF_SYMBOLS;',con=conn).symbol)\n",
    "commods = list(pd.io.sql.read_sql('select symbol from G1_COM_SYMBOLS;',con=conn).symbol)\n",
    "##Light cleanup, nothing perfect –– could set this up using sql. \n",
    "\n",
    "#merge etf lists\n",
    "etfs_c = list(set(etfs).union(set(etfs2)))\n",
    "#leave stocks only \n",
    "stocks_c = list(set(stocks) - set(etfs_c + indexes + ciks + funds + commods))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#setup subset of tickers\n",
    "dow_tickers = list(pd.io.sql.read_sql('select symbol from G1_MI_DOWJLIST;',con=conn).symbol)\n",
    "nasdaq_tickers = list(pd.io.sql.read_sql('select symbol from G1_MI_NASDAQLIST;',con=conn).symbol)\n",
    "sp500_tickers = list(pd.io.sql.read_sql('select symbol from G1_MI_SP500LIST;',con=conn).symbol)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define subset to work with\n",
    "stocksub = dow_tickers\n",
    "#stocksub = sp500_tickers\n",
    "indexsub = ['^IXIC','^GSPC','^DJI']\n",
    "#indexsub = ['^IXIC','^GSPC','^DJI','^VIX','^RUA','^FTSE','^NDX','^N225','GDAXI']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get top US etfs proportionate to stock list\n",
    "num_etfs = int(np.ceil(len(stocksub)/10))\n",
    "profile = get_appended(dependents['P1b1000_CV_PROFILE'],apikey,'P1b1000_CV_PROFILE',tickers = etfs_c)\n",
    "etfsub = list(profile[profile.country == 'US'].sort_values(by='volAvg',ascending=False).symbol[:num_etfs+1])\n",
    "tickersub = stocksub + etfsub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get mutual fund data\n",
    "fundtable = get_appended(dependents['T1_INST_MUTFUNDHOLDERS'],apikey,'T1_INST_MUTFUNDHOLDERS',tickers=tickersub,verbose=False)\n",
    "fundsub = list(fundtable.holder.value_counts().index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mfs = pd.io.sql.read_sql('select * from G1_MF_SYMBOLS;',con=conn)\n",
    "fundsub = list(np.random.choice(list(mfs[mfs.name.isin(fundsub)].symbol),int(np.ceil(len(stocksub)/3))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#establish subset of commods\n",
    "#commodsub = commods[:3]\n",
    "commodsub = commods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get ciks of institutional holders for ciksub\n",
    "instable = get_appended(dependents['T1_INST_HOLDERS'],apikey,'T1_INST_HOLDERS',tickers=tickersub)\n",
    "instsub = list(instable.holder.value_counts().index)\n",
    "instsub = list(np.random.choice(instsub,500)) #account for many missing inst-cik mappings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#retrieve ciks\n",
    "ciklist = pd.io.sql.read_sql('select * from G1_INST_CIKLIST',con=conn)\n",
    "ciksub = list(ciklist[ciklist.name.apply(lambda x: x.lower()).isin([i.lower() for i in instsub])].cik)\n",
    "ciksub = ['000'+str(c) for c in (ciksub)]\n",
    "ciksub = [c for c in ciksub if len(c)==10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dictionary – nothing commodity, crypto, etc. specific\n",
    "d = {'H':stocksub + etfsub + commodsub + fundsub,\n",
    "     'P':stocksub + etfsub + fundsub,\n",
    "     'T':stocksub + etfsub,\n",
    "     'S':stocksub,\n",
    "     'E':etfsub,\n",
    "     'C':commodsub,\n",
    "     'F':ciksub,\n",
    "     'I':indexsub,\n",
    "     'M':fundsub}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "schemas = open(\"schema.sql\", \"a+\")\n",
    "for name, url in dependents.iteritems():\n",
    "    \n",
    "    tablename = '_'.join(name.split('_')[1:])\n",
    "    print(tablename)\n",
    "    \n",
    "    if name[0] == 'U':\n",
    "            continue \n",
    "    elif name[0]=='G': #if ticker info not needed\n",
    "        continue\n",
    "    else:\n",
    "        tab = get_appended(url,apikey,name,tickers=d.get(name[0]),verbose=True)\n",
    "    \n",
    "    if len(tab) == 0: \n",
    "        print(tablename,' FAILED')\n",
    "        #log error\n",
    "        continue\n",
    "    \n",
    "    #load sql\n",
    "    a = pd.io.sql.get_schema(tab,tablename)\n",
    "    c.execute('drop table if exists '+ tablename)\n",
    "    c.execute(a)\n",
    "    tosql = a +';\\n\\n'\n",
    "    schemas.write(tosql)\n",
    "    tab.to_sql(tablename,con=conn,index=False,if_exists='append')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
